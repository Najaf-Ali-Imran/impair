{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54D4n8TALbp9",
        "outputId": "013f31a5-6ec7-489d-d93f-5e6499b102ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "print(\"✅ Drive Mounted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmHYpAFxLg5L",
        "outputId": "2b92bdef-2c15-4a20-9e77-04dc637e2b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Drive Mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import zipfile\n",
        "\n",
        "# --- CONFIGURATION (FINAL, DEFINITIVE PATHS) ---\n",
        "BASE_DRIVE_PATH = '/content/drive/MyDrive/ASL_Project_Files'\n",
        "ZIP_FILE_NAME = 'DATASET_P2.zip'\n",
        "\n",
        "# Define a clean folder name for extraction\n",
        "EXTRACT_FOLDER = 'DATASET_P2_EXTRACTED_CLEAN'\n",
        "\n",
        "# Path to the directory containing the Action Classes (e.g., 'you', 'me', 'hello')\n",
        "# *** THIS IS THE CORRECTED, REDUNDANCY-AWARE PATH ***\n",
        "ACTION_CLASS_PATH = os.path.join(BASE_DRIVE_PATH, EXTRACT_FOLDER, 'DATASET_P2', 'MP_Data')\n",
        "SEQUENCE_LENGTH = 40\n",
        "\n",
        "# --- 1. UNZIPPING DATASET (CLEAN EXTRACTION) ---\n",
        "print(\"--- 1. UNZIPPING DATASET ---\")\n",
        "\n",
        "try:\n",
        "    os.chdir(BASE_DRIVE_PATH)\n",
        "\n",
        "    if os.path.exists(ZIP_FILE_NAME):\n",
        "        # 1. Extract into the new clean folder name\n",
        "        with zipfile.ZipFile(ZIP_FILE_NAME, 'r') as zip_ref:\n",
        "            zip_ref.extractall(os.path.join(BASE_DRIVE_PATH, EXTRACT_FOLDER))\n",
        "        print(\"✅ ZIP extracted successfully into new clean folder.\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"❌ FATAL ERROR: ZIP file '{ZIP_FILE_NAME}' not found.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR during setup/unzip: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. FEATURE EXTRACTION & CONSOLIDATION ---\n",
        "\n",
        "print(\"\\n--- 2. FEATURE EXTRACTION & CONSOLIDATION ---\")\n",
        "\n",
        "# Verify the final path exists AFTER UNZIPPING\n",
        "if not os.path.exists(ACTION_CLASS_PATH):\n",
        "    print(f\"❌ FATAL ERROR: Structure not found at {ACTION_CLASS_PATH}. Stopping.\")\n",
        "    exit()\n",
        "\n",
        "# --- CONSOLIDATION LOGIC (5-LEVEL HIERARCHY) ---\n",
        "ACTION_CLASSES = sorted([d for d in os.listdir(ACTION_CLASS_PATH)\n",
        "                         if os.path.isdir(os.path.join(ACTION_CLASS_PATH, d)) and len(d) > 1])\n",
        "NUM_CLASSES = len(ACTION_CLASSES)\n",
        "HAND_START_INDEX = 33 * 4 + 468 * 3\n",
        "HAND_END_INDEX = HAND_START_INDEX + (21 * 3 * 2)\n",
        "FINAL_FEATURE_SIZE = 126\n",
        "\n",
        "if NUM_CLASSES < 3:\n",
        "    print(f\"❌ FATAL ERROR: Found only {NUM_CLASSES} classes: {ACTION_CLASSES}. Data is severely incomplete.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"✅ Found {NUM_CLASSES} Action Classes: {ACTION_CLASSES}\")\n",
        "\n",
        "X_data = []\n",
        "Y_labels = []\n",
        "label_map = {word: i for i, word in enumerate(ACTION_CLASSES)}\n",
        "corrupted_count = 0\n",
        "\n",
        "# Loop 1: Iterate through each ACTION CLASS (e.g., 'hello')\n",
        "for class_index, action_class in enumerate(tqdm(ACTION_CLASSES, desc=\"Consolidating Classes\")):\n",
        "    class_path = os.path.join(ACTION_CLASS_PATH, action_class)\n",
        "\n",
        "    # Loop 2: Use os.walk to find the Trial/Sequence Folders (e.g., '97', '98')\n",
        "    for root, dirs, files in os.walk(class_path):\n",
        "\n",
        "        # We check for files right away; os.walk handles the nesting\n",
        "        npy_files = sorted([f for f in files if f.endswith('.npy')])\n",
        "\n",
        "        if len(npy_files) == SEQUENCE_LENGTH:\n",
        "            # We found a complete sequence (Trial/Sequence Folder)\n",
        "\n",
        "            sequence_data = []\n",
        "\n",
        "            # Loop 3: Load the 40 .npy files chronologically (0.npy, 1.npy, ...)\n",
        "            for i in range(SEQUENCE_LENGTH):\n",
        "                file_name = f\"{i}.npy\"\n",
        "                file_path = os.path.join(root, file_name)\n",
        "\n",
        "                try:\n",
        "                    frame_features = np.load(file_path)\n",
        "\n",
        "                    # Ensure array is 1D (representing features for a single frame)\n",
        "                    if frame_features.ndim != 1 or frame_features.shape[0] < HAND_END_INDEX:\n",
        "                         raise ValueError(\"Incorrect feature shape\")\n",
        "\n",
        "                    # Extract 126 features from the single frame vector\n",
        "                    hand_landmarks_frame = frame_features[HAND_START_INDEX:HAND_END_INDEX]\n",
        "                    sequence_data.append(hand_landmarks_frame)\n",
        "\n",
        "                except Exception as e:\n",
        "                    corrupted_count += 1\n",
        "                    sequence_data = [] # Discard incomplete sequence\n",
        "                    break # Break out of the frame loop, sequence is corrupt\n",
        "\n",
        "            # If the sequence was loaded successfully (no breaks)\n",
        "            if len(sequence_data) == SEQUENCE_LENGTH:\n",
        "                X_data.append(np.array(sequence_data))\n",
        "                Y_labels.append(class_index)\n",
        "\n",
        "\n",
        "# Convert lists to NumPy arrays and One-Hot Encode Labels\n",
        "X = np.array(X_data)\n",
        "Y = np.array(Y_labels)\n",
        "Y_one_hot = to_categorical(Y, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Print Final Shapes for Validation\n",
        "print(f\"\\nSkipped {corrupted_count} corrupted frames (part of failed sequences).\")\n",
        "print(f\"Total valid sequences extracted: {X.shape[0]}\")\n",
        "print(\"\\n--- FINAL DATA SHAPES ---\")\n",
        "print(f\"X (Sequences): {X.shape} (Samples, Timesteps, Features)\")\n",
        "print(f\"Y (Labels):    {Y_one_hot.shape} (Samples, Classes)\")\n",
        "\n",
        "# --- DELIVERABLE: Save final NumPy arrays back to Drive ---\n",
        "np.save(os.path.join(BASE_DRIVE_PATH, 'X_data_dynamic.npy'), X)\n",
        "np.save(os.path.join(BASE_DRIVE_PATH, 'Y_data_dynamic.npy'), Y_one_hot)\n",
        "\n",
        "print(\"✅ Data consolidation and filtering complete. Ready for LSTM Training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "5stAIBwMPxbJ",
        "outputId": "dab434f3-9e4d-4ef9-bffa-8e899fb2018b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. UNZIPPING DATASET ---\n",
            "✅ ZIP extracted successfully into new clean folder.\n",
            "\n",
            "--- 2. FEATURE EXTRACTION & CONSOLIDATION ---\n",
            "❌ FATAL ERROR: Structure not found at /content/drive/MyDrive/ASL_Project_Files/DATASET_P2_EXTRACTED_CLEAN/DATASET_P2/MP_Data. Stopping.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ASL_Project_Files/DATASET_P2_EXTRACTED_CLEAN/DATASET_P2/MP_Data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2029020738.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# --- CONSOLIDATION LOGIC (5-LEVEL HIERARCHY) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m ACTION_CLASSES = sorted([d for d in os.listdir(ACTION_CLASS_PATH) \n\u001b[0m\u001b[1;32m     49\u001b[0m                          if os.path.isdir(os.path.join(ACTION_CLASS_PATH, d)) and len(d) > 1])\n\u001b[1;32m     50\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACTION_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ASL_Project_Files/DATASET_P2_EXTRACTED_CLEAN/DATASET_P2/MP_Data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "BASE_DRIVE_PATH = '/content/drive/MyDrive/ASL_Project_Files'\n",
        "# Name of the folder to be deleted (created in the previous failed step)\n",
        "FOLDER_TO_DELETE = 'DATASET_P2_EXTRACTED_CLEAN'\n",
        "\n",
        "print(f\"--- ATTEMPTING FORCED DELETION OF {FOLDER_TO_DELETE} ---\")\n",
        "\n",
        "# Navigate to the base directory first (for safety)\n",
        "try:\n",
        "    os.chdir(BASE_DRIVE_PATH)\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ ERROR: Cannot access base path {BASE_DRIVE_PATH}. Check Drive mount.\")\n",
        "    exit()\n",
        "\n",
        "# The rm -rf command forcefully removes a directory and all its contents\n",
        "# We use the full path to ensure the correct folder is targeted.\n",
        "TARGET_PATH = os.path.join(BASE_DRIVE_PATH, FOLDER_TO_DELETE)\n",
        "\n",
        "if os.path.exists(TARGET_PATH):\n",
        "    print(f\"⏳ Deleting folder and all contents: {TARGET_PATH}\")\n",
        "    # ! is used to run shell commands in Colab\n",
        "    !rm -rf \"$TARGET_PATH\"\n",
        "\n",
        "    if not os.path.exists(TARGET_PATH):\n",
        "        print(\"✅ Deletion successful. Folder cleared.\")\n",
        "    else:\n",
        "        print(\"❌ WARNING: Folder still exists after rm -rf. Trying manual unlink.\")\n",
        "        # Fallback to python removal (less reliable for large folders)\n",
        "        # shutil.rmtree(TARGET_PATH)\n",
        "\n",
        "else:\n",
        "    print(f\"✅ Folder {FOLDER_TO_DELETE} was already gone. Proceeding.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb4H3IIoZoFD",
        "outputId": "ba2cda9e-7831-4c0e-be01-065b56075e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ATTEMPTING FORCED DELETION OF DATASET_P2_EXTRACTED_CLEAN ---\n",
            "⏳ Deleting folder and all contents: /content/drive/MyDrive/ASL_Project_Files/DATASET_P2_EXTRACTED_CLEAN\n",
            "✅ Deletion successful. Folder cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import zipfile\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# --- CONFIGURATION (FINAL, DEFINITIVE PATHS) ---\n",
        "BASE_DRIVE_PATH = '/content/drive/MyDrive/ASL_Project_Files'\n",
        "ZIP_FILE_NAME = 'DATASET_P2.zip'\n",
        "EXTRACT_FOLDER = 'DATASET_P2_EXTRACTED_FINAL' # New clean extraction folder name\n",
        "\n",
        "# Path to the base of the extracted content\n",
        "EXTRACTED_BASE_PATH = os.path.join(BASE_DRIVE_PATH, EXTRACT_FOLDER)\n",
        "\n",
        "# --- 1. UNZIPPING DATASET (CLEAN EXTRACTION) ---\n",
        "print(\"--- 1. UNZIPPING DATASET ---\")\n",
        "\n",
        "try:\n",
        "    # Ensure all imports are ready\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive/MyDrive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    os.chdir(BASE_DRIVE_PATH)\n",
        "\n",
        "    if os.path.exists(ZIP_FILE_NAME):\n",
        "        # Create the extraction folder if it doesn't exist\n",
        "        os.makedirs(EXTRACTED_BASE_PATH, exist_ok=True)\n",
        "\n",
        "        # Extract the contents into the clean new folder name\n",
        "        with zipfile.ZipFile(ZIP_FILE_NAME, 'r') as zip_ref:\n",
        "            zip_ref.extractall(EXTRACTED_BASE_PATH)\n",
        "        print(\"✅ ZIP extracted successfully into new clean folder.\")\n",
        "\n",
        "        # --- DIAGNOSTIC STEP: Print contents of the extracted folder ---\n",
        "        print(f\"--- Contents of {EXTRACTED_BASE_PATH}:\")\n",
        "        for item in os.listdir(EXTRACTED_BASE_PATH):\n",
        "            print(f\" - {item}\")\n",
        "        print(\"--------------------------------------------------\")\n",
        "\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"❌ FATAL ERROR: ZIP file '{ZIP_FILE_NAME}' not found at {BASE_DRIVE_PATH}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR during setup/unzip: {e}\")\n",
        "    # Instead of exit(), re-raise the exception to stop execution and provide a traceback\n",
        "    raise\n",
        "\n",
        "# --- 2. FEATURE EXTRACTION & CONSOLIDATION ---\n",
        "\n",
        "print(\"\\n--- 2. FEATURE EXTRACTION & CONSOLIDATION ---\")\n",
        "\n",
        "# --- Dynamic ACTION_CLASS_PATH determination ---\n",
        "# Try to find the 'MP_Data' folder. It could be directly under EXTRACTED_BASE_PATH\n",
        "# or nested under a 'DATASET_P2' folder or 'dataset P2' (with a space).\n",
        "\n",
        "possible_action_paths = [\n",
        "    os.path.join(EXTRACTED_BASE_PATH, 'dataset P2', 'MP_Data'), # Corrected path based on diagnostic output\n",
        "    os.path.join(EXTRACTED_BASE_PATH, 'DATASET_P2', 'MP_Data'),\n",
        "    os.path.join(EXTRACTED_BASE_PATH, 'MP_Data'),\n",
        "]\n",
        "\n",
        "ACTION_CLASS_PATH = None\n",
        "for path_attempt in possible_action_paths:\n",
        "    if os.path.exists(path_attempt):\n",
        "        ACTION_CLASS_PATH = path_attempt\n",
        "        break\n",
        "\n",
        "if ACTION_CLASS_PATH is None:\n",
        "    raise FileNotFoundError(f\"❌ FATAL ERROR: 'MP_Data' structure not found under {EXTRACTED_BASE_PATH}. Checked paths: {possible_action_paths}. Please verify your ZIP file's internal structure.\")\n",
        "\n",
        "print(f\"✅ Action Class path determined: {ACTION_CLASS_PATH}\")\n",
        "\n",
        "\n",
        "# --- CONSOLIDATION LOGIC ---\n",
        "ACTION_CLASSES = sorted([d for d in os.listdir(ACTION_CLASS_PATH)\n",
        "                         if os.path.isdir(os.path.join(ACTION_CLASS_PATH, d)) and len(d) > 1])\n",
        "NUM_CLASSES = len(ACTION_CLASSES)\n",
        "SEQUENCE_LENGTH = 40\n",
        "\n",
        "# Check if we found the intended classes\n",
        "if NUM_CLASSES < 3:\n",
        "    raise ValueError(f\"❌ FATAL ERROR: Found only {NUM_CLASSES} classes: {ACTION_CLASSES}. Data is severely incomplete. Expected at least 3 action classes.\")\n",
        "\n",
        "print(f\"✅ Found {NUM_CLASSES} Action Classes: {ACTION_CLASSES}\")\n",
        "\n",
        "# --- FEATURE INDEXING (126 Features) ---\n",
        "HAND_START_INDEX = 33 * 4 + 468 * 3\n",
        "HAND_END_INDEX = HAND_START_INDEX + (21 * 3 * 2)\n",
        "FINAL_FEATURE_SIZE = 126\n",
        "print(f\"Target Feature Vector Size: {FINAL_FEATURE_SIZE} (X,Y,Z for both hands)\")\n",
        "\n",
        "X_data = []\n",
        "Y_labels = []\n",
        "label_map = {word: i for i, word in enumerate(ACTION_CLASSES)}\n",
        "corrupted_count = 0\n",
        "\n",
        "# Loop 1: Iterate through each ACTION CLASS (e.g., 'hello')\n",
        "for class_index, action_class in enumerate(tqdm(ACTION_CLASSES, desc=\"Consolidating Classes\")):\n",
        "    class_path = os.path.join(ACTION_CLASS_PATH, action_class)\n",
        "\n",
        "    # Loop 2: Use os.walk to find the Trial/Sequence Folders (e.g., '97', '98')\n",
        "    # This automatically handles the Trial/Sequence Folder level\n",
        "    for root, dirs, files in os.walk(class_path):\n",
        "\n",
        "        # Check if we are inside a Trial/Sequence Folder (meaning, we have .npy files)\n",
        "        npy_files = sorted([f for f in files if f.endswith('.npy')])\n",
        "\n",
        "        if len(npy_files) > 0 and len(npy_files) == SEQUENCE_LENGTH:\n",
        "            # We found a complete sequence (Trial/Sequence Folder)\n",
        "\n",
        "            sequence_data = []\n",
        "\n",
        "            # Loop 3: Load the 40 .npy files chronologically (0.npy, 1.npy, ...)\n",
        "            for i in range(SEQUENCE_LENGTH):\n",
        "                file_name = f\"{i}.npy\"\n",
        "                file_path = os.path.join(root, file_name)\n",
        "\n",
        "                try:\n",
        "                    frame_features = np.load(file_path)\n",
        "\n",
        "                    # Ensure array is 1D (representing features for a single frame)\n",
        "                    if frame_features.ndim != 1 or frame_features.shape[0] < HAND_END_INDEX:\n",
        "                         raise ValueError(\"Incorrect feature shape or incomplete frame data.\")\n",
        "\n",
        "                    # Extract 126 features from the single frame vector\n",
        "                    hand_landmarks_frame = frame_features[HAND_START_INDEX:HAND_END_INDEX]\n",
        "                    sequence_data.append(hand_landmarks_frame)\n",
        "\n",
        "                except Exception as e:\n",
        "                    corrupted_count += 1\n",
        "                    sequence_data = [] # Discard incomplete sequence\n",
        "                    break # Break out of the frame loop, sequence is corrupt\n",
        "\n",
        "            # If the sequence was loaded successfully (no breaks)\n",
        "            if len(sequence_data) == SEQUENCE_LENGTH:\n",
        "                X_data.append(np.array(sequence_data))\n",
        "                Y_labels.append(class_index)\n",
        "\n",
        "\n",
        "# Convert lists to NumPy arrays and One-Hot Encode Labels\n",
        "X = np.array(X_data)\n",
        "Y = np.array(Y_labels)\n",
        "Y_one_hot = to_categorical(Y, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Print Final Shapes for Validation\n",
        "print(f\"\\nSkipped {corrupted_count} corrupted frames (part of failed sequences).\")\n",
        "print(f\"Total valid sequences extracted: {X.shape[0]}\")\n",
        "print(\"\\n--- FINAL DATA SHAPES ---\")\n",
        "print(f\"X (Sequences): {X.shape} (Samples, Timesteps, Features)\")\n",
        "print(f\"Y (Labels):    {Y_one_hot.shape} (Samples, Classes)\")\n",
        "\n",
        "# --- DELIVERABLE: Save final NumPy arrays back to Drive ---\n",
        "np.save(os.path.join(BASE_DRIVE_PATH, 'X_data_dynamic.npy'), X)\n",
        "np.save(os.path.join(BASE_DRIVE_PATH, 'Y_data_dynamic.npy'), Y_one_hot)\n",
        "\n",
        "print(\"✅ Data consolidation and filtering complete. Ready for LSTM Training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDy2ArjtcR-Y",
        "outputId": "c7db8937-837b-4c14-b5b5-7dba360c3854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. UNZIPPING DATASET ---\n",
            "✅ ZIP extracted successfully into new clean folder.\n",
            "--- Contents of /content/drive/MyDrive/ASL_Project_Files/DATASET_P2_EXTRACTED_FINAL:\n",
            " - dataset P2\n",
            "--------------------------------------------------\n",
            "\n",
            "--- 2. FEATURE EXTRACTION & CONSOLIDATION ---\n",
            "✅ Action Class path determined: /content/drive/MyDrive/ASL_Project_Files/DATASET_P2_EXTRACTED_FINAL/dataset P2/MP_Data\n",
            "✅ Found 5 Action Classes: ['goodbye', 'hello', 'me', 'thanks', 'you']\n",
            "Target Feature Vector Size: 126 (X,Y,Z for both hands)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Consolidating Classes: 100%|██████████| 5/5 [01:34<00:00, 18.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Skipped 0 corrupted frames (part of failed sequences).\n",
            "Total valid sequences extracted: 500\n",
            "\n",
            "--- FINAL DATA SHAPES ---\n",
            "X (Sequences): (500, 40, 126) (Samples, Timesteps, Features)\n",
            "Y (Labels):    (500, 5) (Samples, Classes)\n",
            "✅ Data consolidation and filtering complete. Ready for LSTM Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical # Used if loading raw arrays later\n",
        "\n",
        "# --- CONFIGURATION (Load Final Arrays) ---\n",
        "BASE_DRIVE_PATH = '/content/drive/MyDrive/ASL_Project_Files'\n",
        "os.chdir(BASE_DRIVE_PATH)\n",
        "\n",
        "print(\"--- 1. LOADING FINAL DYNAMIC ARRAYS ---\")\n",
        "\n",
        "try:\n",
        "    # Load the consolidated X and Y arrays saved from the previous step\n",
        "    X = np.load('X_data_dynamic.npy')\n",
        "    Y = np.load('Y_data_dynamic.npy')\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ FATAL ERROR: Final dynamic arrays (X or Y) not found. Cannot proceed.\")\n",
        "    exit()\n",
        "\n",
        "# Define final parameters from loaded data shapes\n",
        "SEQUENCE_LENGTH = X.shape[1]    # Timesteps (e.g., 40 frames)\n",
        "FINAL_FEATURE_SIZE = X.shape[2] # Features (126 features)\n",
        "NUM_CLASSES = Y.shape[1]        # Classes (e.g., 5 words)\n",
        "\n",
        "print(f\"✅ Data loaded. Shape: {X.shape} (Samples, Timesteps, Features)\")\n",
        "\n",
        "\n",
        "# --- 2. PREDICTION TASK: LSTM MODEL DEFINITION AND TRAINING ---\n",
        "print(\"\\n--- 2. LSTM MODEL TRAINING AND EXPORT ---\")\n",
        "\n",
        "# Split data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train_cat, y_test_cat = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training Samples: {len(X_train)}; Test Samples: {len(X_test)}\")\n",
        "\n",
        "# --- MODEL DEFINITION (LSTM Architecture) ---\n",
        "model = Sequential([\n",
        "    # Masking layer is essential for sequence data (handles any zero-padding)\n",
        "    Masking(mask_value=0., input_shape=(SEQUENCE_LENGTH, FINAL_FEATURE_SIZE)),\n",
        "\n",
        "    # LSTM Layer: The core of the sequence processing model\n",
        "    LSTM(64, return_sequences=False, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Dense output layer\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# --- TRAINING (The slow part with epochs) ---\n",
        "print(\"\\n--- TRAINING LSTM MODEL (This will take time due to sequence processing) ---\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=25, # Standard epochs for sequence models\n",
        "    batch_size=16, # Small batch size helps with sequence complexity\n",
        "    validation_data=(X_test, y_test_cat),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- EXPORT ---\n",
        "MODEL_FILENAME_H5 = 'my_lstm_model_phase2.h5'\n",
        "model.save(os.path.join(BASE_DRIVE_PATH, MODEL_FILENAME_H5))\n",
        "\n",
        "# --- EVALUATION ---\n",
        "loss, accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nFinal LSTM Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Phase 2 Model saved to: {MODEL_FILENAME_H5}\")\n",
        "\n",
        "print(\"\\n--- Phase 2 Prediction Task complete. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7t4Y4s-ph4oP",
        "outputId": "4011658a-694d-4b71-9ce2-97aa35f3d249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. LOADING FINAL DYNAMIC ARRAYS ---\n",
            "✅ Data loaded. Shape: (500, 40, 126) (Samples, Timesteps, Features)\n",
            "\n",
            "--- 2. LSTM MODEL TRAINING AND EXPORT ---\n",
            "Training Samples: 400; Test Samples: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/masking.py:48: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m126\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m48,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m165\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,141\u001b[0m (199.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,141</span> (199.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,141\u001b[0m (199.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,141</span> (199.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TRAINING LSTM MODEL (This will take time due to sequence processing) ---\n",
            "Epoch 1/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.2429 - loss: 1.6691 - val_accuracy: 0.4300 - val_loss: 1.3113\n",
            "Epoch 2/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3941 - loss: 1.3423 - val_accuracy: 0.4300 - val_loss: 1.2547\n",
            "Epoch 3/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3781 - loss: 1.3050 - val_accuracy: 0.6700 - val_loss: 0.6378\n",
            "Epoch 4/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5373 - loss: 0.9807 - val_accuracy: 0.6600 - val_loss: 0.5767\n",
            "Epoch 5/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5870 - loss: 0.8920 - val_accuracy: 0.8600 - val_loss: 0.5196\n",
            "Epoch 6/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6095 - loss: 0.8877 - val_accuracy: 0.7100 - val_loss: 0.4219\n",
            "Epoch 7/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6546 - loss: 0.7525 - val_accuracy: 0.8600 - val_loss: 0.4386\n",
            "Epoch 8/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7001 - loss: 0.6826 - val_accuracy: 0.8500 - val_loss: 0.3523\n",
            "Epoch 9/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7090 - loss: 0.7381 - val_accuracy: 0.7000 - val_loss: 0.5328\n",
            "Epoch 10/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6722 - loss: 0.7580 - val_accuracy: 0.7000 - val_loss: 0.4423\n",
            "Epoch 11/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7824 - loss: 0.5507 - val_accuracy: 0.9200 - val_loss: 0.3079\n",
            "Epoch 12/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5735 - loss: 1.6095 - val_accuracy: 0.5200 - val_loss: 0.9959\n",
            "Epoch 13/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5072 - loss: 1.1460 - val_accuracy: 0.6100 - val_loss: 0.8378\n",
            "Epoch 14/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5387 - loss: 1.0341 - val_accuracy: 0.7500 - val_loss: 0.4237\n",
            "Epoch 15/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6488 - loss: 0.8023 - val_accuracy: 0.7800 - val_loss: 0.3834\n",
            "Epoch 16/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6651 - loss: 0.6953 - val_accuracy: 0.8500 - val_loss: 0.4147\n",
            "Epoch 17/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7330 - loss: 0.6490 - val_accuracy: 0.9400 - val_loss: 0.3316\n",
            "Epoch 18/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7879 - loss: 0.5415 - val_accuracy: 0.8100 - val_loss: 0.3328\n",
            "Epoch 19/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7250 - loss: 0.6908 - val_accuracy: 0.9000 - val_loss: 0.4340\n",
            "Epoch 20/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7349 - loss: 0.6227 - val_accuracy: 0.8900 - val_loss: 0.3777\n",
            "Epoch 21/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7202 - loss: 0.6561 - val_accuracy: 0.8600 - val_loss: 0.3131\n",
            "Epoch 22/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7931 - loss: 0.5606 - val_accuracy: 0.6800 - val_loss: 0.6808\n",
            "Epoch 23/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6439 - loss: 0.8195 - val_accuracy: 0.8000 - val_loss: 0.3796\n",
            "Epoch 24/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7436 - loss: 0.7027 - val_accuracy: 0.9900 - val_loss: 0.2853\n",
            "Epoch 25/25\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7447 - loss: 0.5300 - val_accuracy: 0.9500 - val_loss: 0.2666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final LSTM Model Accuracy: 0.9500\n",
            "✅ Phase 2 Model saved to: my_lstm_model_phase2.h5\n",
            "\n",
            "--- Phase 2 Prediction Task complete. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0addb691"
      },
      "source": [
        "# Task\n",
        "The LSTM model has been successfully trained and evaluated. The final accuracy of the model on the test set is 0.9500."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c382451d"
      },
      "source": [
        "## Execute LSTM Model Training\n",
        "\n",
        "### Subtask:\n",
        "Run the existing code in cell `7t4Y4s-ph4oP` to load the prepared 3D data, split it into training and testing sets, define and compile an LSTM model, train the model for 25 epochs, evaluate its performance, and save the trained model to Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7t4Y5s-ph4oP",
        "outputId": "41b475da-5de3-4541-d062-4bfa8c61f0ae"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical # Used if loading raw arrays later\n",
        "from google.colab import drive\n",
        "\n",
        "# --- CONFIGURATION (Load Final Arrays) ---\n",
        "BASE_DRIVE_PATH = '/content/drive/MyDrive/ASL_Project_Files'\n",
        "\n",
        "# Ensure Drive is mounted before trying to access files\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(BASE_DRIVE_PATH)\n",
        "\n",
        "print(\"--- 1. LOADING FINAL DYNAMIC ARRAYS ---\")\n",
        "\n",
        "try:\n",
        "    # Load the consolidated X and Y arrays saved from the previous step\n",
        "    X = np.load('X_data_dynamic.npy')\n",
        "    Y = np.load('Y_data_dynamic.npy')\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ FATAL ERROR: Final dynamic arrays (X or Y) not found. Cannot proceed.\")\n",
        "    exit()\n",
        "\n",
        "# Define final parameters from loaded data shapes\n",
        "SEQUENCE_LENGTH = X.shape[1]    # Timesteps (e.g., 40 frames)\n",
        "FINAL_FEATURE_SIZE = X.shape[2] # Features (126 features)\n",
        "NUM_CLASSES = Y.shape[1]        # Classes (e.g., 5 words)\n",
        "\n",
        "print(f\"✅ Data loaded. Shape: {X.shape} (Samples, Timesteps, Features)\")\n",
        "\n",
        "\n",
        "# --- 2. PREDICTION TASK: LSTM MODEL DEFINITION AND TRAINING ---\n",
        "print(\"\\n--- 2. LSTM MODEL TRAINING AND EXPORT ---\")\n",
        "\n",
        "# Split data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train_cat, y_test_cat = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training Samples: {len(X_train)}; Test Samples: {len(X_test)}\")\n",
        "\n",
        "# --- MODEL DEFINITION (LSTM Architecture) ---\n",
        "model = Sequential([\n",
        "    # Masking layer is essential for sequence data (handles any zero-padding)\n",
        "    Masking(mask_value=0., input_shape=(SEQUENCE_LENGTH, FINAL_FEATURE_SIZE)),\n",
        "\n",
        "    # LSTM Layer: The core of the sequence processing model\n",
        "    LSTM(64, return_sequences=False, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Dense output layer\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# --- TRAINING (The slow part with epochs) ---\n",
        "print(\"\\n--- TRAINING LSTM MODEL (This will take time due to sequence processing) ---\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=100, # Changed from 25 to 100 epochs\n",
        "    batch_size=16, # Small batch size helps with sequence complexity\n",
        "    validation_data=(X_test, y_test_cat),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- EXPORT ---\n",
        "MODEL_FILENAME_H5 = 'my_lstm_model_phase2.h5'\n",
        "model.save(os.path.join(BASE_DRIVE_PATH, MODEL_FILENAME_H5))\n",
        "\n",
        "# --- EVALUATION ---\n",
        "loss, accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nFinal LSTM Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Phase 2 Model saved to: {MODEL_FILENAME_H5}\")\n",
        "\n",
        "print(\"\\n--- Phase 2 Prediction Task complete.---\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. LOADING FINAL DYNAMIC ARRAYS ---\n",
            "✅ Data loaded. Shape: (500, 40, 126) (Samples, Timesteps, Features)\n",
            "\n",
            "--- 2. LSTM MODEL TRAINING AND EXPORT ---\n",
            "Training Samples: 400; Test Samples: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/masking.py:48: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m126\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m48,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m165\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,141\u001b[0m (199.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,141</span> (199.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,141\u001b[0m (199.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,141</span> (199.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TRAINING LSTM MODEL (This will take time due to sequence processing) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.2658 - loss: 1.5898 - val_accuracy: 0.4600 - val_loss: 1.2085\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3869 - loss: 1.2793 - val_accuracy: 0.8400 - val_loss: 0.9282\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5073 - loss: 1.0647 - val_accuracy: 0.8300 - val_loss: 0.5423\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5836 - loss: 0.9940 - val_accuracy: 0.9000 - val_loss: 0.4460\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6864 - loss: 0.7230 - val_accuracy: 0.8800 - val_loss: 0.4493\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6058 - loss: 1.0308 - val_accuracy: 0.9900 - val_loss: 0.5417\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7306 - loss: 0.7744 - val_accuracy: 0.9300 - val_loss: 0.3195\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8348 - loss: 0.5042 - val_accuracy: 0.8900 - val_loss: 0.3768\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7191 - loss: 0.6878 - val_accuracy: 0.9700 - val_loss: 0.3287\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8267 - loss: 0.5725 - val_accuracy: 0.9000 - val_loss: 0.3444\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8176 - loss: 0.6463 - val_accuracy: 0.9200 - val_loss: 0.2886\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8693 - loss: 0.3941 - val_accuracy: 0.9900 - val_loss: 0.0494\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9047 - loss: 0.2563 - val_accuracy: 0.9400 - val_loss: 0.1528\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7562 - loss: 0.7877 - val_accuracy: 0.8000 - val_loss: 0.6084\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7341 - loss: 0.7191 - val_accuracy: 0.8300 - val_loss: 0.4471\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7614 - loss: 0.9509 - val_accuracy: 0.7400 - val_loss: 0.6080\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6409 - loss: 0.8047 - val_accuracy: 0.7400 - val_loss: 0.4659\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7235 - loss: 0.8177 - val_accuracy: 0.7400 - val_loss: 0.4242\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7673 - loss: 0.6342 - val_accuracy: 0.9000 - val_loss: 0.3605\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7865 - loss: 0.5531 - val_accuracy: 0.8400 - val_loss: 0.3351\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8254 - loss: 0.4689 - val_accuracy: 0.9500 - val_loss: 0.3170\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8597 - loss: 0.4150 - val_accuracy: 0.9700 - val_loss: 0.1817\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8547 - loss: 0.3478 - val_accuracy: 0.9600 - val_loss: 0.2132\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8752 - loss: 0.3371 - val_accuracy: 0.9900 - val_loss: 0.1482\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8725 - loss: 0.3424 - val_accuracy: 0.9900 - val_loss: 0.0831\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9278 - loss: 0.2378 - val_accuracy: 0.9900 - val_loss: 0.0730\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9121 - loss: 0.2351 - val_accuracy: 0.9800 - val_loss: 0.1288\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9422 - loss: 0.2417 - val_accuracy: 0.9900 - val_loss: 0.0763\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9311 - loss: 0.2238 - val_accuracy: 0.9900 - val_loss: 0.0417\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9580 - loss: 0.1462 - val_accuracy: 0.9900 - val_loss: 0.0281\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9686 - loss: 0.1053 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9692 - loss: 0.1314 - val_accuracy: 0.9200 - val_loss: 0.1571\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9075 - loss: 0.2377 - val_accuracy: 0.9900 - val_loss: 0.1165\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9498 - loss: 0.1765 - val_accuracy: 0.9900 - val_loss: 0.0413\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9555 - loss: 0.1414 - val_accuracy: 0.9900 - val_loss: 0.0368\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9915 - loss: 0.0499 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9804 - loss: 0.0628 - val_accuracy: 0.9900 - val_loss: 0.0434\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9649 - loss: 0.1445 - val_accuracy: 0.8900 - val_loss: 0.1656\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8868 - loss: 0.2871 - val_accuracy: 0.9900 - val_loss: 0.0923\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9506 - loss: 0.1516 - val_accuracy: 0.9900 - val_loss: 0.0563\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9323 - loss: 0.1690 - val_accuracy: 1.0000 - val_loss: 0.0193\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9530 - loss: 0.1956 - val_accuracy: 0.9800 - val_loss: 0.0736\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8924 - loss: 0.2773 - val_accuracy: 0.9100 - val_loss: 0.1733\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9403 - loss: 0.2042 - val_accuracy: 0.9900 - val_loss: 0.0297\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9701 - loss: 0.1566 - val_accuracy: 0.9800 - val_loss: 0.1161\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9117 - loss: 0.1926 - val_accuracy: 0.9800 - val_loss: 0.1311\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8597 - loss: 2.2556 - val_accuracy: 0.4700 - val_loss: 1.3107\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6182 - loss: 0.8422 - val_accuracy: 0.7100 - val_loss: 0.7735\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7133 - loss: 0.7165 - val_accuracy: 0.7200 - val_loss: 0.5403\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7327 - loss: 0.6020 - val_accuracy: 0.9900 - val_loss: 0.4407\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8082 - loss: 0.4433 - val_accuracy: 1.0000 - val_loss: 0.3049\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8190 - loss: 0.5185 - val_accuracy: 0.5300 - val_loss: 0.7881\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6560 - loss: 0.7503 - val_accuracy: 0.9300 - val_loss: 0.5306\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7426 - loss: 0.5815 - val_accuracy: 0.9900 - val_loss: 0.3028\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8574 - loss: 0.4005 - val_accuracy: 0.9900 - val_loss: 0.1541\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8511 - loss: 0.3221 - val_accuracy: 0.9800 - val_loss: 0.0705\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9182 - loss: 0.2171 - val_accuracy: 0.9900 - val_loss: 0.0564\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9149 - loss: 0.2273 - val_accuracy: 0.9900 - val_loss: 0.0322\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8996 - loss: 0.2428 - val_accuracy: 0.9900 - val_loss: 0.0252\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9114 - loss: 0.4784 - val_accuracy: 0.8700 - val_loss: 0.3107\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8360 - loss: 0.4527 - val_accuracy: 1.0000 - val_loss: 0.0919\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8801 - loss: 0.3087 - val_accuracy: 0.8400 - val_loss: 0.8844\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7464 - loss: 0.9449 - val_accuracy: 0.9800 - val_loss: 0.2813\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7867 - loss: 0.5424 - val_accuracy: 0.9900 - val_loss: 0.1807\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7841 - loss: 0.5007 - val_accuracy: 0.9900 - val_loss: 0.1187\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8624 - loss: 0.3766 - val_accuracy: 0.9800 - val_loss: 0.0999\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9058 - loss: 0.2825 - val_accuracy: 0.9800 - val_loss: 0.0702\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8734 - loss: 0.5544 - val_accuracy: 0.7300 - val_loss: 0.7713\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6689 - loss: 1.0265 - val_accuracy: 0.8300 - val_loss: 0.3970\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8152 - loss: 0.5136 - val_accuracy: 0.8400 - val_loss: 0.3190\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8169 - loss: 0.4287 - val_accuracy: 0.8400 - val_loss: 0.2605\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8328 - loss: 0.3933 - val_accuracy: 0.8700 - val_loss: 0.2115\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8967 - loss: 0.3146 - val_accuracy: 0.9100 - val_loss: 0.1784\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9046 - loss: 0.2878 - val_accuracy: 0.9600 - val_loss: 0.2309\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8239 - loss: 0.4370 - val_accuracy: 0.9800 - val_loss: 0.1325\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8316 - loss: 0.9206 - val_accuracy: 0.9500 - val_loss: 0.1953\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8753 - loss: 0.3277 - val_accuracy: 0.9900 - val_loss: 0.1519\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9090 - loss: 0.2926 - val_accuracy: 0.9900 - val_loss: 0.0902\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9035 - loss: 0.2305 - val_accuracy: 0.9900 - val_loss: 0.0579\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9096 - loss: 0.2275 - val_accuracy: 0.9600 - val_loss: 0.1355\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9417 - loss: 0.1987 - val_accuracy: 0.9900 - val_loss: 0.0564\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9458 - loss: 0.1552 - val_accuracy: 0.9900 - val_loss: 0.0454\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9264 - loss: 0.1668 - val_accuracy: 0.9800 - val_loss: 0.0347\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9568 - loss: 0.1460 - val_accuracy: 0.9600 - val_loss: 0.0941\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9543 - loss: 0.1651 - val_accuracy: 0.9900 - val_loss: 0.0637\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9401 - loss: 0.1492 - val_accuracy: 0.9800 - val_loss: 0.0468\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9788 - loss: 0.0976 - val_accuracy: 0.9900 - val_loss: 0.0438\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9566 - loss: 0.1211 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9622 - loss: 0.1110 - val_accuracy: 0.9900 - val_loss: 0.0231\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9373 - loss: 0.1525 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9653 - loss: 0.1221 - val_accuracy: 0.9900 - val_loss: 0.0368\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9665 - loss: 0.1192 - val_accuracy: 0.9900 - val_loss: 0.0258\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9249 - loss: 0.2551 - val_accuracy: 0.8100 - val_loss: 0.4170\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8834 - loss: 0.3472 - val_accuracy: 0.9200 - val_loss: 0.1841\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9331 - loss: 0.1978 - val_accuracy: 1.0000 - val_loss: 0.1038\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9440 - loss: 0.1601 - val_accuracy: 0.9800 - val_loss: 0.0657\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9718 - loss: 0.1160 - val_accuracy: 0.9900 - val_loss: 0.0521\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9624 - loss: 0.1311 - val_accuracy: 0.9900 - val_loss: 0.0433\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9694 - loss: 0.1008 - val_accuracy: 0.9900 - val_loss: 0.0438\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0959 - val_accuracy: 0.9600 - val_loss: 0.0776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final LSTM Model Accuracy: 0.9600\n",
            "✅ Phase 2 Model saved to: my_lstm_model_phase2.h5\n",
            "\n",
            "--- Phase 2 Prediction Task complete.---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04e0378e"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of the LSTM model training and evaluation, including the final accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f33c72b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The LSTM model was successfully trained and evaluated, achieving a final accuracy of 0.9500 on the test set.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   An LSTM model was successfully trained and evaluated using prepared 3D data.\n",
        "*   The final accuracy of the trained LSTM model on the test set was reported as 0.9500.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The high accuracy of 0.9500 suggests that the LSTM model performs very well on the given task.\n",
        "*   Given the successful training and high accuracy, the next step could involve deploying the model or further investigating its performance on specific types of data points.\n"
      ]
    }
  ]
}